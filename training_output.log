INFO: ================================================================================
INFO:                     å®Œæ•´è®­ç»ƒæµæ°´çº¿                    
INFO: ================================================================================
INFO: 
[æ­¥éª¤ 1] åŠ è½½è®­ç»ƒæ•°æ®...
INFO: âœ… æ•°æ®åŠ è½½æˆåŠŸ: (2000, 7)
INFO: ç‰¹å¾åˆ—: ['Temperature', 'Humidity', 'WindSpeed', 'EDP', 'Hour', 'DayOfWeek', 'Month']
INFO: 
[æ­¥éª¤ 2] é…ç½®è®­ç»ƒå‚æ•°...
INFO: è®­ç»ƒé…ç½®: epochs=10, batch_size=32
INFO: 
[æ­¥éª¤ 3] åˆ›å»ºè®­ç»ƒæµæ°´çº¿...
INFO: TrainPipeline initialized with output_dir=./outputs/training_run_1
INFO: 
[æ­¥éª¤ 4] å¼€å§‹è®­ç»ƒ...

INFO: ============================================================
INFO: Starting Training Pipeline
INFO: ============================================================
INFO: 
[Step 1/9] Data Preprocessing...
INFO: å¼€å§‹æ•°æ®é¢„å¤„ç†...
INFO: å¼€å§‹æ•°æ®æ¸…æ´—...
/home/severin/Codelib/YS/src/preprocessing/data_preprocessor.py:53: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.
  df = df.fillna(method='ffill').fillna(method='bfill')
INFO: æ•°æ®æ¸…æ´—å®Œæˆï¼Œæ ·æœ¬æ•°: 2000
INFO: æå–æ—¶é—´ç‰¹å¾...
INFO: é¢„å¤„ç†å®Œæˆï¼Œåºåˆ—æ•°: 1980, ç‰¹å¾ç»´åº¦: (1980, 20, 3)
INFO:   Train: X=(1980, 20, 3), y=(1980,)
INFO: 
[Step 2/9] Training Parallel CNN-LSTM-Attention Model...
2026-01-16 16:14:49.339164: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.
2026-01-16 16:14:49.339426: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2026-01-16 16:14:49.380800: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX_VNNI AVX_VNNI_INT8 AVX_NE_CONVERT FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2026-01-16 16:14:50.281331: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2026-01-16 16:14:50.281637: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.
2026-01-16 16:14:50.418222: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)
INFO: æ¨¡å‹æ„å»ºå®Œæˆ
INFO: å‚æ•°é‡: 20,307
Epoch 1/10
[1m 1/62[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1:40[0m 2s/step - loss: 22567.7969 - mae: 149.4238[1m10/62[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 6ms/step - loss: 22557.2016 - mae: 149.4500 [1m22/62[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 5ms/step - loss: 22285.9012 - mae: 148.5255[1m34/62[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 5ms/step - loss: 22002.1498 - mae: 147.5527[1m47/62[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 5ms/step - loss: 21564.2666 - mae: 145.9798[1m60/62[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 4ms/step - loss: 20808.5401 - mae: 142.8577[1m62/62[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m2s[0m 5ms/step - loss: 16212.1074 - mae: 121.2691
Epoch 2/10
[1m 1/62[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 17ms/step - loss: 2201.7239 - mae: 37.4142[1m14/62[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 4ms/step - loss: 2250.2054 - mae: 37.6598 [1m27/62[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 4ms/step - loss: 2228.6301 - mae: 37.5444[1m39/62[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 4ms/step - loss: 2180.7097 - mae: 37.2135[1m50/62[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 4ms/step - loss: 2130.0240 - mae: 36.8263[1m62/62[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 4ms/step - loss: 1822.7552 - mae: 34.1556
Epoch 3/10
[1m 1/62[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - loss: 1770.8208 - mae: 34.7932[1m13/62[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 4ms/step - loss: 1416.0822 - mae: 30.5706 [1m27/62[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 4ms/step - loss: 1390.0124 - mae: 30.3214[1m41/62[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 4ms/step - loss: 1388.6921 - mae: 30.2261[1m54/62[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 4ms/step - loss: 1394.0105 - mae: 30.2641[1m62/62[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 4ms/step - loss: 1396.4315 - mae: 30.1747
Epoch 4/10
[1m 1/62[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 18ms/step - loss: 1115.5906 - mae: 26.8412[1m14/62[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 4ms/step - loss: 1381.4678 - mae: 29.7142 [1m27/62[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 4ms/step - loss: 1388.4214 - mae: 29.7970[1m39/62[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 4ms/step - loss: 1387.3661 - mae: 29.7745[1m53/62[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 4ms/step - loss: 1386.1155 - mae: 29.7565[1m62/62[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 4ms/step - loss: 1355.7697 - mae: 29.3439
Epoch 5/10
[1m 1/62[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 17ms/step - loss: 1055.2772 - mae: 26.9825[1m12/62[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 5ms/step - loss: 1087.6609 - mae: 26.8019 [1m23/62[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 5ms/step - loss: 1104.1406 - mae: 26.9200[1m36/62[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 4ms/step - loss: 1117.8634 - mae: 27.0109[1m49/62[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 4ms/step - loss: 1123.7415 - mae: 27.0515[1m62/62[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 4ms/step - loss: 1133.9273 - mae: 27.1648[1m62/62[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 4ms/step - loss: 1186.1882 - mae: 27.7412
Epoch 6/10
[1m 1/62[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 16ms/step - loss: 1278.3254 - mae: 28.6482[1m13/62[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 4ms/step - loss: 1346.5617 - mae: 29.4083 [1m25/62[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 4ms/step - loss: 1346.1650 - mae: 29.6368[1m39/62[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 4ms/step - loss: 1320.7141 - mae: 29.3839[1m52/62[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 4ms/step - loss: 1295.5880 - mae: 29.0883[1m62/62[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 4ms/step - loss: 1225.1061 - mae: 28.1640
Epoch 7/10
[1m 1/62[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 17ms/step - loss: 1323.3962 - mae: 30.0749[1m14/62[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 4ms/step - loss: 1203.8456 - mae: 27.9158 [1m27/62[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 4ms/step - loss: 1180.2412 - mae: 27.5584[1m42/62[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 4ms/step - loss: 1181.0136 - mae: 27.5522[1m56/62[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 4ms/step - loss: 1184.8636 - mae: 27.5887[1m62/62[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 4ms/step - loss: 1179.4814 - mae: 27.4388
Epoch 8/10
[1m 1/62[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 16ms/step - loss: 893.6036 - mae: 22.2741[1m11/62[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 5ms/step - loss: 1049.6938 - mae: 25.3381[1m26/62[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 4ms/step - loss: 1081.4504 - mae: 26.1158[1m42/62[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 4ms/step - loss: 1086.8943 - mae: 26.2944[1m58/62[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 4ms/step - loss: 1099.1660 - mae: 26.4719[1m62/62[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 4ms/step - loss: 1135.1157 - mae: 26.9201
Epoch 9/10
[1m 1/62[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 16ms/step - loss: 1216.5205 - mae: 28.5480[1m16/62[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 3ms/step - loss: 983.6390 - mae: 24.9136  [1m31/62[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 3ms/step - loss: 1011.7162 - mae: 25.1562[1m46/62[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m0s[0m 3ms/step - loss: 1031.1030 - mae: 25.4063[1m62/62[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 3ms/step - loss: 1048.8652 - mae: 25.6528[1m62/62[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 4ms/step - loss: 1097.4946 - mae: 26.3890
Epoch 10/10
[1m 1/62[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 17ms/step - loss: 1178.1853 - mae: 26.9419[1m14/62[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 4ms/step - loss: 1096.3983 - mae: 26.4433 [1m27/62[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 4ms/step - loss: 1096.3415 - mae: 26.5831[1m41/62[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 4ms/step - loss: 1108.2960 - mae: 26.7639[1m57/62[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 4ms/step - loss: 1116.3220 - mae: 26.8701[1m62/62[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 4ms/step - loss: 1150.0182 - mae: 27.3132
INFO:   Final train loss: 1150.0182
INFO: 
[Step 3/9] Extracting Deep Learning Parameters (CAM & Attention)...
[1m 1/62[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m2s[0m 35ms/step[1m47/62[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 1ms/step [1m62/62[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 1ms/step
[1m 1/62[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 74ms/step[1m37/62[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 1ms/step [1m62/62[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 3ms/step[1m62/62[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 3ms/step
INFO:   CAM: (1980, 10)
INFO:   Attention: (1980, 20)
INFO: 
[Step 4/9] Clustering DLP Features...
INFO: CAM èšç±»æ‹Ÿåˆ...
INFO: CAM èšç±»å®Œæˆï¼Œèšç±»æ•°: 3
INFO: Attentionæƒé‡èšç±»æ‹Ÿåˆ...
INFO: Attentionèšç±»å®Œæˆï¼Œèšç±»: ['Early', 'Other', 'Early']
INFO:   CAM clusters: [650 870 460]
INFO:   Attention types: {'Early': 1590, 'Other': 390}
INFO: 
[Step 5/9] Sn State Classification...
INFO: è®¡ç®—Snå°ºåº¦ä¼°è®¡å™¨...
INFO: ä¸­ä½æ•°: 146.2809, Snå°ºåº¦: 14.4536
INFO: K-meansèšç±»...
INFO: èšç±»ä¸­å¿ƒ: [-1.03924579  1.5286441   0.11955863]
INFO: çŠ¶æ€æ˜ å°„: {np.int64(0): 'Lower', np.int64(2): 'Normal', np.int64(1): 'Peak'}
INFO:   State distribution: {'Normal': 885, 'Lower': 615, 'Peak': 480}
INFO: 
[Step 6/9] Feature Discretization...
ERROR: 
âŒ è®­ç»ƒå¤±è´¥: QuantileDiscretizer.__init__() got an unexpected keyword argument 'labels'
Traceback (most recent call last):
  File "/home/severin/Codelib/YS/scripts/run_training.py", line 93, in main
    results = pipeline.run(train_data)
              ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/severin/Codelib/YS/src/pipeline/train_pipeline.py", line 163, in run
    discrete_data = self._step6_discretize(train_data, edp_states, cam_clusters, attention_types)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/severin/Codelib/YS/src/pipeline/train_pipeline.py", line 292, in _step6_discretize
    self.discretizer = QuantileDiscretizer(
                       ^^^^^^^^^^^^^^^^^^^^
TypeError: QuantileDiscretizer.__init__() got an unexpected keyword argument 'labels'
